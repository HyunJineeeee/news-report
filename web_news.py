# web_news.py
import requests
import pandas as pd
import os
import smtplib
import time
import re
from pathlib import Path
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import google.generativeai as genai
from datetime import datetime, timedelta
import trafilatura
import difflib
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============== ì„¤ì • ==============
KEYWORDS = ["ì¼í•™ìŠµë³‘í–‰", "ì§ì—…í›ˆë ¨", "ê³ ìš©ë…¸ë™ë¶€", "í•œêµ­ì‚°ì—…ì¸ë ¥ê³µë‹¨"]
DATA_DIR = Path("data")
SIMILARITY_THRESHOLD = 0.4

KEYWORD_COLORS = {
    "ì¼í•™ìŠµë³‘í–‰": "#3498db", "ì§ì—…í›ˆë ¨": "#e67e22",
    "ê³ ìš©ë…¸ë™ë¶€": "#7f8c8d", "í•œêµ­ì‚°ì—…ì¸ë ¥ê³µë‹¨": "#2c3e50"
}

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
EMAIL_USER = os.environ.get("EMAIL_USER")
EMAIL_PASSWORD = os.environ.get("EMAIL_PASSWORD")
EMAIL_RECEIVER = os.environ.get("EMAIL_RECEIVER")
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ============== ìœ í‹¸ ==============
def clean_html(raw_html):
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.replace("&quot;", "'").replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")

def normalize_title(title):
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', title)

def is_similar(text1, text2):
    if not text1 or not text2: return False
    return difflib.SequenceMatcher(None, text1, text2).ratio() >= SIMILARITY_THRESHOLD

# ============== AI ê¸°ëŠ¥ (í•µì‹¬ ìˆ˜ì •: ì•ˆì „ í•„í„° í•´ì œ) ==============
def generate_content_safe(prompt):
    if not GEMINI_API_KEY: return ""
    
    # â˜… ì•ˆì „ ì„¤ì •: ë‰´ìŠ¤ ë‚´ìš©ì´ ì°¨ë‹¨ë˜ì§€ ì•Šë„ë¡ í•„í„°ë§ ìˆ˜ì¤€ì„ ë‚®ì¶¤
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    
    # â˜… ëª¨ë¸ ë³€ê²½: ê°€ì¥ ì•ˆì •ì ì¸ 'gemini-pro' ì‚¬ìš©
    try:
        model = genai.GenerativeModel('gemini-pro') 
        response = model.generate_content(prompt, safety_settings=safety_settings)
        
        # ì‘ë‹µì´ ì •ìƒì ì¸ì§€ í™•ì¸
        if response.text:
            return response.text.strip()
        else:
            print("âš ï¸ [AI ì‘ë‹µ ì—†ìŒ] ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return ""
            
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ì— ìƒì„¸ ì¶œë ¥
        print(f"âŒ [AI ìƒì„± ì‹¤íŒ¨] ì›ì¸: {e}")
        return ""

def summarize_article(text: str) -> str:
    prompt = (
        "ë„ˆëŠ” ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ë´‡ì´ì•¼. ì•„ë˜ ê¸°ì‚¬ ë³¸ë¬¸ì„ ì½ê³  í•µì‹¬ ë‚´ìš©ì„ 2~3ì¤„ë¡œ ìš”ì•½í•´.\n"
        "í˜•ì‹: '- 'ë¡œ ì‹œì‘í•˜ëŠ” ê°œì¡°ì‹ ë¬¸ì¥.\n"
        "ì¡°ê±´: ê°ì •ì„ ë°°ì œí•˜ê³  ê±´ì¡°í•œ ë³´ê³ ì„œì²´ ì‚¬ìš©.\n"
        "ì£¼ì˜: ì„œë¡  ì—†ì´ ë°”ë¡œ ìš”ì•½ ë‚´ìš©ë§Œ ì¶œë ¥.\n\n"
        f"ê¸°ì‚¬ ë³¸ë¬¸:\n{text[:3500]}" # í† í° ì œí•œ ê³ ë ¤í•˜ì—¬ ê¸¸ì´ ì¡°ì •
    )
    result = generate_content_safe(prompt)
    if result: return result
    return f"- (AI ìš”ì•½ ì‹¤íŒ¨) ì›ë¬¸ í™•ì¸ í•„ìš”"

def repair_snippet(snippet: str) -> str:
    prompt = (
        "ë„ˆëŠ” ë¬¸ì¥ êµì • ì „ë¬¸ê°€ì•¼. ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” ê¸°ì‚¬ ìš”ì•½ì˜ ì¼ë¶€ì¸ë° ë¬¸ì¥ì´ ì˜ë ¤ ìˆì–´.\n"
        "ë‚´ìš©ì„ ì¶”ë¡ í•˜ì—¬ **ì™„ì „í•œ í•˜ë‚˜ì˜ ìš”ì•½ ë¬¸ì¥**ìœ¼ë¡œ ë‹¤ë“¬ì–´ì¤˜.\n"
        "í˜•ì‹: '- 'ë¡œ ì‹œì‘.\n\n"
        f"ì…ë ¥ í…ìŠ¤íŠ¸:\n{snippet}"
    )
    result = generate_content_safe(prompt)
    # AIê°€ ì„±ê³µí–ˆìœ¼ë©´ ê·¸ ê²°ê³¼ ë°˜í™˜, ì‹¤íŒ¨í–ˆìœ¼ë©´ ì›ë³¸(ë„¤ì´ë²„ ìš”ì•½)ì´ë¼ë„ ë³´ì—¬ì¤Œ
    if result: return result
    return f"- {snippet}"

# ============== ë³¸ë¬¸ ì¶”ì¶œ (ë„¤ì´ë²„ ì „ìš©) ==============
def extract_article_content(url: str) -> str:
    if not url: return ""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://news.naver.com/'
    }
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        if resp.status_code == 200:
            text = trafilatura.extract(resp.text, include_comments=False, include_tables=False)
            if text and len(text) >= 50: return text
        return ""
    except: return ""

# ============== ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ==============
def crawl_naver_news(keyword, target_date_str):
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        print("[ERROR] ë„¤ì´ë²„ API í‚¤ ëˆ„ë½")
        return []

    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    params = {"query": keyword, "display": 100, "start": 1, "sort": "date"}

    try:
        resp = requests.get(url, headers=headers, params=params)
        resp.raise_for_status()
        data = resp.json()
    except Exception as e:
        print(f"   [API Error] {e}")
        return []

    rows = []
    collected_at = pd.Timestamp.now(tz="Asia/Seoul").strftime("%Y-%m-%d %H:%M")
    
    for item in data.get('items', []):
        try:
            pub_date_dt = datetime.strptime(item['pubDate'], "%a, %d %b %Y %H:%M:%S +0900")
            pub_date_str = pub_date_dt.strftime("%Y-%m-%d %H:%M")
            pub_date_day = pub_date_dt.strftime("%Y-%m-%d")
        except: continue

        if pub_date_day != target_date_str: continue
            
        raw_link = item['link']
        if "news.naver.com" not in raw_link: continue 

        title = clean_html(item['title'])
        desc = clean_html(item['description'])
        
        rows.append({
            "í‚¤ì›Œë“œ": keyword,
            "ì œëª©": title,
            "ì›ë¬¸ë§í¬": raw_link,
            "ì¶œì²˜": "NaverNews",
            "ë°œí–‰ì¼(KST)": pub_date_str,
            "ìˆ˜ì§‘ì‹œê°(KST)": collected_at,
            "ìš”ì•½": "",
            "_api_desc": desc,
            "_title_norm": normalize_title(title)
        })
    return rows

# ============== ì´ë©”ì¼ ë°œì†¡ ==============
def send_email_report(df_new, target_date_str):
    if not EMAIL_USER or not EMAIL_PASSWORD or not EMAIL_RECEIVER: return
    if df_new.empty: return

    subject = f"[ì¼ë³‘ë¦¬í¬íŠ¸] {target_date_str} ì£¼ìš” ë‰´ìŠ¤ ì•Œë¦¼"

    html_body = f"""
    <div style="font-family: 'Malgun Gothic', sans-serif; background-color: #f4f4f4; padding: 20px; color: #333;">
        <div style="max-width: 700px; margin: 0 auto; background-color: #ffffff; padding: 30px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
            <div style="text-align: center; margin-bottom: 30px; border-bottom: 2px solid #555; padding-bottom: 20px;">
                <h1 style="color: #2c3e50; font-size: 24px; margin: 0;">ğŸ“° {target_date_str} ë‰´ìŠ¤ ë¦¬í¬íŠ¸</h1>
                <p style="color: #7f8c8d; font-size: 14px; margin-top: 10px;">
                    ì–´ì œ ìˆ˜ì§‘ëœ ì´ <span style="color:#e67e22; font-weight:bold;">{len(df_new)}</span>ê±´ì˜ ê¸°ì‚¬ ìš”ì•½ì…ë‹ˆë‹¤.
                </p>
            </div>
    """

    grouped = df_new.groupby("í‚¤ì›Œë“œ")
    for kw in KEYWORDS:
        if kw in grouped.groups:
            group_df = grouped.get_group(kw)
            kw_color = KEYWORD_COLORS.get(kw, "#333333")
            
            html_body += f"""
            <div style="margin-bottom: 30px;">
                <div style="background-color: {kw_color}; color: white; padding: 6px 15px; display: inline-block; border-radius: 15px; font-weight: bold; font-size: 16px; margin-bottom: 15px;">
                    # {kw}
                </div>
            """
            for idx, row in group_df.iterrows():
                title = row['ì œëª©']
                link = row['ì›ë¬¸ë§í¬']
                date = row['ë°œí–‰ì¼(KST)']
                summary = row['ìš”ì•½']
                summary_html = summary.replace('\n', '<br>')
                
                # ì‹¤íŒ¨ ë¬¸êµ¬ê°€ ë³´ì´ë©´ íšŒìƒ‰, ì•„ë‹ˆë©´ í‚¤ì›Œë“œ ìƒ‰ìƒ
                border_color = kw_color if summary and "ì‹¤íŒ¨" not in summary else "#ddd"
                
                html_body += f"""
                <div style="border: 1px solid #e0e0e0; border-radius: 8px; padding: 20px; margin-bottom: 15px; background-color: #fff;">
                    <a href="{link}" target="_blank" style="font-size: 18px; font-weight: bold; color: #2c3e50; text-decoration: none; display: block; margin-bottom: 8px; line-height: 1.4;">
                        {title}
                    </a>
                    <div style="font-size: 12px; color: #95a5a6; margin-bottom: 15px;">
                        {date}
                    </div>
                    <div style="background-color: #f9f9f9; padding: 15px; border-left: 4px solid {border_color}; color: #555; font-size: 14px; line-height: 1.6; border-radius: 4px;">
                        {summary_html}
                    </div>
                    <div style="text-align: right; margin-top: 10px;">
                        <a href="{link}" target="_blank" style="display: inline-block; background-color: #ecf0f1; color: #555; padding: 5px 12px; border-radius: 4px; text-decoration: none; font-size: 12px;">
                            ì›ë¬¸ ë³´ëŸ¬ê°€ê¸° â†’
                        </a>
                    </div>
                </div>
                """
            html_body += '</div>'

    html_body += """
            <div style="text-align: center; margin-top: 40px; font-size: 12px; color: #bdc3c7; border-top: 1px solid #eee; padding-top: 20px;">
                Automated by GitHub Actions & Naver API
            </div>
        </div>
    </div>
    """

    try:
        msg = MIMEMultipart()
        msg['Subject'] = subject
        msg['From'] = EMAIL_USER
        msg['To'] = EMAIL_RECEIVER
        msg.attach(MIMEText(html_body, 'html'))

        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(EMAIL_USER, EMAIL_PASSWORD)
            server.send_message(msg)
        print(f"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ! ({subject})")
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

# ============== ë©”ì¸ ==============
def main():
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    now_kst = pd.Timestamp.now(tz="Asia/Seoul")
    yesterday_kst = now_kst - pd.Timedelta(days=1)
    target_date_str = yesterday_kst.strftime("%Y-%m-%d")
    print(f"ğŸ¯ íƒ€ê²Ÿ ë‚ ì§œ(ì–´ì œ): {target_date_str}")

    all_path = DATA_DIR / "ALL.csv"
    req_cols = ["í‚¤ì›Œë“œ","ì œëª©","ì›ë¬¸ë§í¬","ë°œí–‰ì¼(KST)","ìˆ˜ì§‘ì‹œê°(KST)","ì¶œì²˜","ìš”ì•½","_api_desc","_title_norm"]
    
    if all_path.exists():
        df_existing = pd.read_csv(all_path, dtype=str, encoding="utf-8-sig")
        for c in req_cols: 
            if c not in df_existing.columns: df_existing[c] = ""
        existing_titles = list(df_existing["_title_norm"].dropna().astype(str))
    else:
        df_existing = pd.DataFrame(columns=req_cols)
        existing_titles = []

    raw_rows = []
    for kw in KEYWORDS:
        print(f"ğŸ“¡ ìˆ˜ì§‘ ì¤‘ (Naver): {kw}...")
        raw_rows.extend(crawl_naver_news(kw, target_date_str))
        time.sleep(0.5)
    
    if not raw_rows: 
        print(f"ğŸ“… {target_date_str} ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    unique_rows = []
    for row in raw_rows:
        new_title_norm = row["_title_norm"]
        is_duplicate = False
        for exist_title in existing_titles:
            if is_similar(new_title_norm, exist_title):
                is_duplicate = True
                break
        if is_duplicate: continue
        for accepted in unique_rows:
            if is_similar(new_title_norm, accepted["_title_norm"]):
                is_duplicate = True
                break
        if not is_duplicate:
            unique_rows.append(row)

    df_to_process = pd.DataFrame(unique_rows)
    print(f"ğŸ” {len(raw_rows)}ê±´ ì¤‘ ì¤‘ë³µ ì œê±° í›„ {len(df_to_process)}ê±´ ì²˜ë¦¬ ì‹œì‘.")

    processed_rows = []
    for idx, row in df_to_process.iterrows():
        print(f"   Processing: {row['ì œëª©'][:20]}...")
        target_url = row["ì›ë¬¸ë§í¬"]
        keyword = row["í‚¤ì›Œë“œ"]
        api_desc = row["_api_desc"]
        
        content = extract_article_content(target_url)
        summary = ""
        
        if content:
            if keyword not in content and keyword not in row['ì œëª©']:
                print(f"   âŒ [ì œì™¸] ë³¸ë¬¸ì— '{keyword}' ì—†ìŒ")
                continue 
            summary = summarize_article(content)
            time.sleep(2)
        
        if not summary or "ë¶€ì¡±í•©ë‹ˆë‹¤" in summary:
            # ì‹¤íŒ¨ ì‹œ ë³µì› (ì•ˆì „ ì„¤ì • í•´ì œë¨)
            restored = repair_snippet(api_desc)
            if restored == api_desc: 
                summary = f"{api_desc} (AI ì‘ë™ ì‹¤íŒ¨)"
            else:
                summary = restored
            
        row["ìš”ì•½"] = summary
        processed_rows.append(row)

    if processed_rows:
        df_new_processed = pd.DataFrame(processed_rows)
        send_email_report(df_new_processed, target_date_str)
    else:
        print("ğŸ§¹ ì²˜ë¦¬í•  ì‹ ê·œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        df_new_processed = pd.DataFrame(columns=req_cols)

    df_final_new = df_new_processed[req_cols] if not df_new_processed.empty else pd.DataFrame(columns=req_cols)
    combined = pd.concat([df_existing, df_final_new], ignore_index=True)
    combined = combined.drop_duplicates(subset=["_title_norm"], keep="last")
    combined = combined.sort_values("ìˆ˜ì§‘ì‹œê°(KST)", ascending=False)

    display_cols = ["í‚¤ì›Œë“œ","ì œëª©","ìš”ì•½","ì›ë¬¸ë§í¬","ë°œí–‰ì¼(KST)","ìˆ˜ì§‘ì‹œê°(KST)"]
    combined[display_cols].to_csv(DATA_DIR / "ALL.csv", index=False, encoding="utf-8-sig")
    
    if not df_new_processed.empty:
        df_new_processed[display_cols].to_csv(DATA_DIR / "NEW_latest.csv", index=False, encoding="utf-8-sig")
    
    print("ğŸ‰ ì™„ë£Œ")

if __name__ == "__main__":
    main()
