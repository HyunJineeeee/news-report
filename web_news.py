# web_news.py
import requests
import pandas as pd
import os
import smtplib
import time
import re
from pathlib import Path
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import google.generativeai as genai
from datetime import datetime, timedelta
import trafilatura
import difflib
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============== ì„¤ì • ==============
KEYWORDS = ["ì¼í•™ìŠµë³‘í–‰", "ì§ì—…í›ˆë ¨", "ê³ ìš©ë…¸ë™ë¶€", "í•œêµ­ì‚°ì—…ì¸ë ¥ê³µë‹¨"]
DATA_DIR = Path("data")
SIMILARITY_THRESHOLD = 0.5 

KEYWORD_COLORS = {
    "ì¼í•™ìŠµë³‘í–‰": "#3498db",      # íŒŒë‘
    "ì§ì—…í›ˆë ¨": "#e67e22",        # ì£¼í™©
    "ê³ ìš©ë…¸ë™ë¶€": "#7f8c8d",      # íšŒìƒ‰
    "í•œêµ­ì‚°ì—…ì¸ë ¥ê³µë‹¨": "#2c3e50" # ë‚¨ìƒ‰
}

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
EMAIL_USER = os.environ.get("EMAIL_USER")
EMAIL_PASSWORD = os.environ.get("EMAIL_PASSWORD")
EMAIL_RECEIVER = os.environ.get("EMAIL_RECEIVER")
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ============== ìœ í‹¸ ==============
def clean_html(raw_html):
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.replace("&quot;", "'").replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")

def normalize_title(title):
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', title)

def is_similar(text1, text2):
    if not text1 or not text2: return False
    return difflib.SequenceMatcher(None, text1, text2).ratio() >= SIMILARITY_THRESHOLD

# ============== AI & ë³¸ë¬¸ ì¶”ì¶œ ==============
def extract_article_content(url: str) -> str:
    if not url: return ""
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Referer': 'https://www.naver.com/'
    }

    try:
        # 1. Trafilatura ì‹œë„
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)
            if text and len(text) >= 50: return text

        # 2. Requests + Trafilatura ì¬ì‹œë„
        resp = requests.get(url, headers=headers, timeout=10, verify=False)
        resp.encoding = resp.apparent_encoding 
        if resp.status_code == 200:
            text = trafilatura.extract(resp.text, include_comments=False)
            if text and len(text) >= 50: return text
            
        return ""
    except Exception:
        return ""

def summarize_with_gemini(text: str) -> str:
    if not GEMINI_API_KEY or not text: return ""
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = (
            "ë„ˆëŠ” ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ë´‡ì´ì•¼. ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ë‚´ìš©ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.\n"
            "í˜•ì‹: '- 'ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥.\n"
            "ì¡°ê±´ 1: '~í•¨', '~ì„', '~ê²ƒìœ¼ë¡œ ë³´ì„' ë“± ê°„ê²°í•œ ë³´ê³ ì„œì²´ ì‚¬ìš©.\n"
            "ì¡°ê±´ 2: ë¶ˆí•„ìš”í•œ ì„œìˆ ì–´ ì œê±°.\n\n"
            f"í…ìŠ¤íŠ¸:\n{text[:4000]}"
        )
        response = model.generate_content(prompt)
        return response.text.strip()
    except: return ""

# ============== ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ==============
def crawl_naver_news(keyword, target_date_str):
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        print("[ERROR] ë„¤ì´ë²„ API í‚¤ ëˆ„ë½")
        return []

    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    
    params = {"query": keyword, "display": 100, "start": 1, "sort": "date"}

    try:
        resp = requests.get(url, headers=headers, params=params)
        resp.raise_for_status()
        data = resp.json()
    except Exception as e:
        print(f"   [API Error] {e}")
        return []

    rows = []
    collected_at = pd.Timestamp.now(tz="Asia/Seoul").strftime("%Y-%m-%d %H:%M")
    
    for item in data.get('items', []):
        try:
            pub_date_dt = datetime.strptime(item['pubDate'], "%a, %d %b %Y %H:%M:%S +0900")
            pub_date_str = pub_date_dt.strftime("%Y-%m-%d %H:%M")
            pub_date_day = pub_date_dt.strftime("%Y-%m-%d")
        except: continue

        if pub_date_day != target_date_str: continue
            
        raw_link = item['link']
        original_link = item['originallink']
        
        target_url = ""
        if "news.naver.com" in raw_link:
            target_url = raw_link 
        else:
            target_url = original_link if original_link else raw_link

        if not target_url: continue

        title = clean_html(item['title'])
        desc = clean_html(item['description'])
        
        rows.append({
            "í‚¤ì›Œë“œ": keyword,
            "ì œëª©": title,
            "ì›ë¬¸ë§í¬": target_url,
            "ì¶œì²˜": "NaverAPI",
            "ë°œí–‰ì¼(KST)": pub_date_str,
            "ìˆ˜ì§‘ì‹œê°(KST)": collected_at,
            "ìš”ì•½": "",
            "_api_desc": desc,
            "_title_norm": normalize_title(title)
        })
    return rows

# ============== ì´ë©”ì¼ ë°œì†¡ ==============
def send_email_report(df_new, target_date_str):
    if not EMAIL_USER or not EMAIL_PASSWORD or not EMAIL_RECEIVER: return
    if df_new.empty: return

    subject = f"[ì¼ë³‘ë¦¬í¬íŠ¸] {target_date_str} ì£¼ìš” ë‰´ìŠ¤ ì•Œë¦¼"

    html_body = f"""
    <div style="font-family: 'Malgun Gothic', sans-serif; background-color: #f4f4f4; padding: 20px; color: #333;">
        <div style="max-width: 700px; margin: 0 auto; background-color: #ffffff; padding: 30px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
            <div style="text-align: center; margin-bottom: 30px; border-bottom: 2px solid #555; padding-bottom: 20px;">
                <h1 style="color: #2c3e50; font-size: 24px; margin: 0;">ğŸ“° {target_date_str} ë‰´ìŠ¤ ë¦¬í¬íŠ¸</h1>
                <p style="color: #7f8c8d; font-size: 14px; margin-top: 10px;">
                    ì–´ì œ ìˆ˜ì§‘ëœ ì´ <span style="color:#e67e22; font-weight:bold;">{len(df_new)}</span>ê±´ì˜ ê¸°ì‚¬ ìš”ì•½ì…ë‹ˆë‹¤.
                </p>
            </div>
    """

    grouped = df_new.groupby("í‚¤ì›Œë“œ")
    for kw in KEYWORDS:
        if kw in grouped.groups:
            group_df = grouped.get_group(kw)
            kw_color = KEYWORD_COLORS.get(kw, "#333333")
            
            html_body += f"""
            <div style="margin-bottom: 30px;">
                <div style="background-color: {kw_color}; color: white; padding: 6px 15px; display: inline-block; border-radius: 15px; font-weight: bold; font-size: 16px; margin-bottom: 15px;">
                    # {kw}
                </div>
            """
            for idx, row in group_df.iterrows():
                title = row['ì œëª©']
                link = row['ì›ë¬¸ë§í¬']
                date = row['ë°œí–‰ì¼(KST)']
                summary = row['ìš”ì•½']
                summary_html = summary.replace('\n', '<br>')
                
                # ìš”ì•½ì´ ìˆìœ¼ë©´ í‚¤ì›Œë“œ ìƒ‰ìƒ, ì—†ìœ¼ë©´(ì •ë§ ì‹¤íŒ¨ì‹œ) íšŒìƒ‰
                border_color = kw_color if summary else "#ddd"
                
                html_body += f"""
                <div style="border: 1px solid #e0e0e0; border-radius: 8px; padding: 20px; margin-bottom: 15px; background-color: #fff;">
                    <a href="{link}" target="_blank" style="font-size: 18px; font-weight: bold; color: #2c3e50; text-decoration: none; display: block; margin-bottom: 8px; line-height: 1.4;">
                        {title}
                    </a>
                    <div style="font-size: 12px; color: #95a5a6; margin-bottom: 15px;">
                        {date}
                    </div>
                    <div style="background-color: #f9f9f9; padding: 15px; border-left: 4px solid {border_color}; color: #555; font-size: 14px; line-height: 1.6; border-radius: 4px;">
                        {summary_html}
                    </div>
                    <div style="text-align: right; margin-top: 10px;">
                        <a href="{link}" target="_blank" style="display: inline-block; background-color: #ecf0f1; color: #555; padding: 5px 12px; border-radius: 4px; text-decoration: none; font-size: 12px;">
                            ì›ë¬¸ ë³´ëŸ¬ê°€ê¸° â†’
                        </a>
                    </div>
                </div>
                """
            html_body += '</div>'

    html_body += """
            <div style="text-align: center; margin-top: 40px; font-size: 12px; color: #bdc3c7; border-top: 1px solid #eee; padding-top: 20px;">
                Automated by GitHub Actions & Naver API
            </div>
        </div>
    </div>
    """

    try:
        msg = MIMEMultipart()
        msg['Subject'] = subject
        msg['From'] = EMAIL_USER
        msg['To'] = EMAIL_RECEIVER
        msg.attach(MIMEText(html_body, 'html'))

        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(EMAIL_USER, EMAIL_PASSWORD)
            server.send_message(msg)
        print(f"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ! ({subject})")
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

# ============== ë©”ì¸ ==============
def main():
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    now_kst = pd.Timestamp.now(tz="Asia/Seoul")
    yesterday_kst = now_kst - pd.Timedelta(days=1)
    target_date_str = yesterday_kst.strftime("%Y-%m-%d")
    print(f"ğŸ¯ íƒ€ê²Ÿ ë‚ ì§œ(ì–´ì œ): {target_date_str}")

    all_path = DATA_DIR / "ALL.csv"
    req_cols = ["í‚¤ì›Œë“œ","ì œëª©","ì›ë¬¸ë§í¬","ë°œí–‰ì¼(KST)","ìˆ˜ì§‘ì‹œê°(KST)","ì¶œì²˜","ìš”ì•½","_api_desc","_title_norm"]
    
    if all_path.exists():
        df_existing = pd.read_csv(all_path, dtype=str, encoding="utf-8-sig")
        for c in req_cols: 
            if c not in df_existing.columns: df_existing[c] = ""
        existing_titles = list(df_existing["_title_norm"].dropna().astype(str))
    else:
        df_existing = pd.DataFrame(columns=req_cols)
        existing_titles = []

    # í¬ë¡¤ë§
    raw_rows = []
    for kw in KEYWORDS:
        print(f"ğŸ“¡ ìˆ˜ì§‘ ì¤‘ (Naver): {kw}...")
        raw_rows.extend(crawl_naver_news(kw, target_date_str))
        time.sleep(0.5)
    
    if not raw_rows: 
        print(f"ğŸ“… {target_date_str} ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì¤‘ë³µ ì œê±° (ìœ ì‚¬ë„ 50%)
    unique_rows = []
    print("ğŸ§¹ ì¤‘ë³µ ì œê±°(ìœ ì‚¬ë„ 50%) ìˆ˜í–‰ ì¤‘...")
    for row in raw_rows:
        new_title_norm = row["_title_norm"]
        is_duplicate = False
        for exist_title in existing_titles:
            if is_similar(new_title_norm, exist_title):
                is_duplicate = True
                break
        if is_duplicate: continue
        for accepted in unique_rows:
            if is_similar(new_title_norm, accepted["_title_norm"]):
                is_duplicate = True
                break
        if not is_duplicate:
            unique_rows.append(row)

    df_to_process = pd.DataFrame(unique_rows)
    print(f"ğŸ” {len(raw_rows)}ê±´ ì¤‘ ì¤‘ë³µ ì œê±° í›„ {len(df_to_process)}ê±´ ì²˜ë¦¬ ì‹œì‘.")

    processed_rows = []
    for idx, row in df_to_process.iterrows():
        print(f"   Processing: {row['ì œëª©'][:20]}...")
        target_url = row["ì›ë¬¸ë§í¬"]
        keyword = row["í‚¤ì›Œë“œ"]
        api_desc = row["_api_desc"] # ë„¤ì´ë²„ê°€ ì¤€ 3ì¤„ ìš”ì•½(raw text)
        
        # 1. ë³¸ë¬¸ ì¶”ì¶œ ì‹œë„
        content = extract_article_content(target_url)
        summary = ""
        
        if content:
            # ë³¸ë¬¸ í•„í„°ë§
            if keyword not in content and keyword not in row['ì œëª©']:
                print(f"   âŒ [ì œì™¸] ë³¸ë¬¸ì— '{keyword}' ì—†ìŒ")
                continue 
            
            # ë³¸ë¬¸ìœ¼ë¡œ AI ìš”ì•½
            summary = summarize_with_gemini(content)
            time.sleep(2)
        
        # 2. â˜… ì¤‘ìš”: ë³¸ë¬¸ ì‹¤íŒ¨ ì‹œ -> ë„¤ì´ë²„ ì„¤ëª…ê¸€(api_desc)ì„ AIì—ê²Œ ë‹¤ë“¬ê²Œ ì‹œí‚´
        if not summary or "ë¶€ì¡±í•©ë‹ˆë‹¤" in summary:
            if api_desc:
                # "ë³¸ë¬¸ ì ‘ì† ë¶ˆê°€" ë©˜íŠ¸ ì‚­ì œí•˜ê³ , ê·¸ëƒ¥ ì„¤ëª…ì„ ìš”ì•½í•´ë²„ë¦¼
                summary = summarize_with_gemini(api_desc)
                if not summary: # í˜¹ì‹œë¼ë„ AIê°€ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ì‚¬ìš©
                    summary = f"- {api_desc}"
            else:
                summary = "- ìš”ì•½í•  ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            
        row["ìš”ì•½"] = summary
        processed_rows.append(row)

    if processed_rows:
        df_new_processed = pd.DataFrame(processed_rows)
        send_email_report(df_new_processed, target_date_str)
    else:
        print("ğŸ§¹ ì²˜ë¦¬í•  ì‹ ê·œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        df_new_processed = pd.DataFrame(columns=req_cols)

    df_final_new = df_new_processed[req_cols] if not df_new_processed.empty else pd.DataFrame(columns=req_cols)
    combined = pd.concat([df_existing, df_final_new], ignore_index=True)
    combined = combined.drop_duplicates(subset=["_title_norm"], keep="last")
    combined = combined.sort_values("ìˆ˜ì§‘ì‹œê°(KST)", ascending=False)

    display_cols = ["í‚¤ì›Œë“œ","ì œëª©","ìš”ì•½","ì›ë¬¸ë§í¬","ë°œí–‰ì¼(KST)","ìˆ˜ì§‘ì‹œê°(KST)"]
    combined[display_cols].to_csv(DATA_DIR / "ALL.csv", index=False, encoding="utf-8-sig")
    
    if not df_new_processed.empty:
        df_new_processed[display_cols].to_csv(DATA_DIR / "NEW_latest.csv", index=False, encoding="utf-8-sig")
    
    print("ğŸ‰ ì™„ë£Œ")

if __name__ == "__main__":
    main()
