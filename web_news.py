# web_news.py
import requests
import pandas as pd
import os
import smtplib
import time
import re
import json
from pathlib import Path
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta
import trafilatura
import difflib
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============== ì„¤ì • ==============
KEYWORDS = ["ì¼í•™ìŠµë³‘í–‰", "ì§ì—…í›ˆë ¨", "ê³ ìš©ë…¸ë™ë¶€", "í•œêµ­ì‚°ì—…ì¸ë ¥ê³µë‹¨"]
DATA_DIR = Path("data")

# â˜… ì¤‘ë³µ ì œê±° ê¸°ì¤€: 10% (0.1) ì´ìƒ ë¹„ìŠ·í•˜ë©´ ì œê±°
SIMILARITY_THRESHOLD = 0.1 

KEYWORD_COLORS = {
    "ì¼í•™ìŠµë³‘í–‰": "#3498db", "ì§ì—…í›ˆë ¨": "#e67e22",
    "ê³ ìš©ë…¸ë™ë¶€": "#7f8c8d", "í•œêµ­ì‚°ì—…ì¸ë ¥ê³µë‹¨": "#2c3e50"
}

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
EMAIL_USER = os.environ.get("EMAIL_USER")
EMAIL_PASSWORD = os.environ.get("EMAIL_PASSWORD")
EMAIL_RECEIVER = os.environ.get("EMAIL_RECEIVER")
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")

# ============== ìœ í‹¸ ==============
def clean_html(raw_html):
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    # íŠ¹ìˆ˜ë¬¸ì ë° ì§€ì €ë¶„í•œ ê¸°í˜¸ ì •ë¦¬
    cleantext = cleantext.replace("&quot;", "'").replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")
    return cleantext

def normalize_for_comparison(title):
    """
    ì¤‘ë³µ ë¹„êµë¥¼ ìœ„í•´ ì œëª©ì„ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
    1. ì§€ì •ëœ í‚¤ì›Œë“œ ì œê±° (ì¼í•™ìŠµë³‘í–‰, ì§ì—…í›ˆë ¨ ë“±)
    2. íŠ¹ìˆ˜ë¬¸ì/ê³µë°± ì œê±°
    """
    # 1. í‚¤ì›Œë“œ ì œê±°
    for kw in KEYWORDS:
        title = title.replace(kw, "")
    
    # 2. í•œê¸€/ì˜ì–´/ìˆ«ìë§Œ ë‚¨ê¸°ê³  ë‹¤ ì œê±°
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', title)

def is_similar(text1, text2):
    """
    ë‘ í…ìŠ¤íŠ¸(í‚¤ì›Œë“œ ì œê±°ë¨)ì˜ ìœ ì‚¬ë„ê°€ 10% ì´ìƒì¸ì§€ í™•ì¸
    """
    if not text1 or not text2: return False
    
    # ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)
    similarity = difflib.SequenceMatcher(None, text1, text2).ratio()
    
    # 10% ì´ìƒì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼ (True ë°˜í™˜)
    return similarity >= SIMILARITY_THRESHOLD

# ============== AI ê¸°ëŠ¥ (REST API + ì‹¤íŒ¨ ì‹œ ì¡°ìš©íˆ ì²˜ë¦¬) ==============
def call_gemini_silent(prompt):
    if not GEMINI_API_KEY: return None
    
    # ì‹œë„í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (v1beta)
    models = ["gemini-1.5-flash", "gemini-pro"]
    
    headers = {"Content-Type": "application/json"}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]
    }

    for model_name in models:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={GEMINI_API_KEY}"
        try:
            response = requests.post(url, headers=headers, json=data, timeout=10)
            if response.status_code == 200:
                return response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
        except:
            continue
            
    return None # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (ì—ëŸ¬ ì¶œë ¥ X)

def summarize_article(text: str) -> str:
    prompt = (
        "ë‰´ìŠ¤ ìš”ì•½ ë´‡. ë‹¤ìŒ ë‚´ìš©ì„ 2ì¤„ ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½.\n"
        "í˜•ì‹: '- 'ë¡œ ì‹œì‘.\n"
        f"ë‚´ìš©:\n{text[:3000]}"
    )
    return call_gemini_silent(prompt)

def repair_snippet(snippet: str) -> str:
    prompt = (
        "ë¬¸ì¥ ì™„ì„± ë´‡. ì•„ë˜ ë¬¸ì¥ì€ ì˜ë ¤ìˆë‹¤. ë‚´ìš©ì„ ì¶”ì¸¡í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì™„ì„±í•˜ë¼.\n"
        "í˜•ì‹: '- 'ë¡œ ì‹œì‘.\n"
        f"ì…ë ¥:\n{snippet}"
    )
    return call_gemini_silent(prompt)

# ============== ë³¸ë¬¸ ì¶”ì¶œ (ë„¤ì´ë²„ ì „ìš©) ==============
def extract_article_content(url: str) -> str:
    if not url: return ""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://news.naver.com/'
    }
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        if resp.status_code == 200:
            text = trafilatura.extract(resp.text, include_comments=False, include_tables=False)
            if text and len(text) >= 50: return text
        return ""
    except: return ""

# ============== ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ==============
def crawl_naver_news(keyword, target_date_str):
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        print("[ERROR] ë„¤ì´ë²„ API í‚¤ ëˆ„ë½")
        return []

    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    params = {"query": keyword, "display": 100, "start": 1, "sort": "date"}

    try:
        resp = requests.get(url, headers=headers, params=params)
        resp.raise_for_status()
        data = resp.json()
    except:
        return []

    rows = []
    collected_at = pd.Timestamp.now(tz="Asia/Seoul").strftime("%Y-%m-%d %H:%M")
    
    for item in data.get('items', []):
        try:
            pub_date_dt = datetime.strptime(item['pubDate'], "%a, %d %b %Y %H:%M:%S +0900")
            pub_date_str = pub_date_dt.strftime("%Y-%m-%d %H:%M")
            pub_date_day = pub_date_dt.strftime("%Y-%m-%d")
        except: continue

        if pub_date_day != target_date_str: continue
            
        raw_link = item['link']
        if "news.naver.com" not in raw_link: continue 

        title = clean_html(item['title'])
        desc = clean_html(item['description'])
        
        # ì¤‘ë³µ ë¹„êµìš© ì œëª© ìƒì„± (í‚¤ì›Œë“œ ì œê±°ë¨)
        norm_title = normalize_for_comparison(title)
        
        rows.append({
            "í‚¤ì›Œë“œ": keyword,
            "ì œëª©": title,
            "ì›ë¬¸ë§í¬": raw_link,
            "ì¶œì²˜": "NaverNews",
            "ë°œí–‰ì¼(KST)": pub_date_str,
            "ìˆ˜ì§‘ì‹œê°(KST)": collected_at,
            "ìš”ì•½": "",
            "_api_desc": desc,
            "_title_norm": norm_title
        })
    return rows

# ============== ì´ë©”ì¼ ë°œì†¡ ==============
def send_email_report(df_new, target_date_str):
    if not EMAIL_USER or not EMAIL_PASSWORD or not EMAIL_RECEIVER: return
    if df_new.empty: return

    subject = f"[ì¼ë³‘ë¦¬í¬íŠ¸] {target_date_str} ì£¼ìš” ë‰´ìŠ¤ ì•Œë¦¼"

    html_body = f"""
    <div style="font-family: 'Malgun Gothic', sans-serif; background-color: #f4f4f4; padding: 20px; color: #333;">
        <div style="max-width: 700px; margin: 0 auto; background-color: #ffffff; padding: 30px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
            <div style="text-align: center; margin-bottom: 30px; border-bottom: 2px solid #555; padding-bottom: 20px;">
                <h1 style="color: #2c3e50; font-size: 24px; margin: 0;">ğŸ“° {target_date_str} ë‰´ìŠ¤ ë¦¬í¬íŠ¸</h1>
                <p style="color: #7f8c8d; font-size: 14px; margin-top: 10px;">
                    ì–´ì œ ìˆ˜ì§‘ëœ ì´ <span style="color:#e67e22; font-weight:bold;">{len(df_new)}</span>ê±´ì˜ ê¸°ì‚¬ ìš”ì•½ì…ë‹ˆë‹¤.
                </p>
            </div>
    """

    grouped = df_new.groupby("í‚¤ì›Œë“œ")
    for kw in KEYWORDS:
        if kw in grouped.groups:
            group_df = grouped.get_group(kw)
            kw_color = KEYWORD_COLORS.get(kw, "#333333")
            
            html_body += f"""
            <div style="margin-bottom: 30px;">
                <div style="background-color: {kw_color}; color: white; padding: 6px 15px; display: inline-block; border-radius: 15px; font-weight: bold; font-size: 16px; margin-bottom: 15px;">
                    # {kw}
                </div>
            """
            for idx, row in group_df.iterrows():
                title = row['ì œëª©']
                link = row['ì›ë¬¸ë§í¬']
                date = row['ë°œí–‰ì¼(KST)']
                summary = row['ìš”ì•½']
                
                # ìš”ì•½ ì„±ê³µ ì‹œ ì¤„ë°”ê¿ˆ
                summary_html = summary.replace('\n', '<br>')
                
                # í…Œë‘ë¦¬ ìƒ‰ìƒ: AI ì‹¤íŒ¨/ì„±ê³µ ìƒê´€ì—†ì´ í‚¤ì›Œë“œ ìƒ‰ìƒ ìœ ì§€ (ê¹”ë”í•˜ê²Œ ë³´ì´ê¸° ìœ„í•¨)
                border_color = kw_color 
                
                html_body += f"""
                <div style="border: 1px solid #e0e0e0; border-radius: 8px; padding: 20px; margin-bottom: 15px; background-color: #fff;">
                    <a href="{link}" target="_blank" style="font-size: 18px; font-weight: bold; color: #2c3e50; text-decoration: none; display: block; margin-bottom: 8px; line-height: 1.4;">
                        {title}
                    </a>
                    <div style="font-size: 12px; color: #95a5a6; margin-bottom: 15px;">
                        {date}
                    </div>
                    <div style="background-color: #f9f9f9; padding: 15px; border-left: 4px solid {border_color}; color: #555; font-size: 14px; line-height: 1.6; border-radius: 4px;">
                        {summary_html}
                    </div>
                    <div style="text-align: right; margin-top: 10px;">
                        <a href="{link}" target="_blank" style="display: inline-block; background-color: #ecf0f1; color: #555; padding: 5px 12px; border-radius: 4px; text-decoration: none; font-size: 12px;">
                            ì›ë¬¸ ë³´ëŸ¬ê°€ê¸° â†’
                        </a>
                    </div>
                </div>
                """
            html_body += '</div>'

    html_body += """
            <div style="text-align: center; margin-top: 40px; font-size: 12px; color: #bdc3c7; border-top: 1px solid #eee; padding-top: 20px;">
                Automated by GitHub Actions & Naver API
            </div>
        </div>
    </div>
    """

    try:
        msg = MIMEMultipart()
        msg['Subject'] = subject
        msg['From'] = EMAIL_USER
        msg['To'] = EMAIL_RECEIVER
        msg.attach(MIMEText(html_body, 'html'))

        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(EMAIL_USER, EMAIL_PASSWORD)
            server.send_message(msg)
        print(f"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ! ({subject})")
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

# ============== ë©”ì¸ ==============
def main():
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    now_kst = pd.Timestamp.now(tz="Asia/Seoul")
    yesterday_kst = now_kst - pd.Timedelta(days=1)
    target_date_str = yesterday_kst.strftime("%Y-%m-%d")
    print(f"ğŸ¯ íƒ€ê²Ÿ ë‚ ì§œ(ì–´ì œ): {target_date_str}")

    all_path = DATA_DIR / "ALL.csv"
    req_cols = ["í‚¤ì›Œë“œ","ì œëª©","ì›ë¬¸ë§í¬","ë°œí–‰ì¼(KST)","ìˆ˜ì§‘ì‹œê°(KST)","ì¶œì²˜","ìš”ì•½","_api_desc","_title_norm"]
    
    if all_path.exists():
        df_existing = pd.read_csv(all_path, dtype=str, encoding="utf-8-sig")
        for c in req_cols: 
            if c not in df_existing.columns: df_existing[c] = ""
        existing_titles = list(df_existing["_title_norm"].dropna().astype(str))
    else:
        df_existing = pd.DataFrame(columns=req_cols)
        existing_titles = []

    raw_rows = []
    for kw in KEYWORDS:
        print(f"ğŸ“¡ ìˆ˜ì§‘ ì¤‘ (Naver): {kw}...")
        raw_rows.extend(crawl_naver_news(kw, target_date_str))
        time.sleep(0.5)
    
    if not raw_rows: 
        print(f"ğŸ“… {target_date_str} ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # â˜…â˜…â˜… ê°•ë ¥í•œ ì¤‘ë³µ ì œê±° (í‚¤ì›Œë“œ ì œì™¸ í›„ 10% ìœ ì‚¬ë„ ì²´í¬) â˜…â˜…â˜…
    unique_rows = []
    print(f"ğŸ§¹ ì¤‘ë³µ ì œê±°(ìœ ì‚¬ë„ {int(SIMILARITY_THRESHOLD*100)}%) ìˆ˜í–‰ ì¤‘...")
    
    for row in raw_rows:
        new_title_norm = row["_title_norm"]
        is_duplicate = False
        
        # 1. ê¸°ì¡´ DBì™€ ë¹„êµ
        for exist_title in existing_titles:
            if is_similar(new_title_norm, exist_title):
                is_duplicate = True
                break
        if is_duplicate: continue
        
        # 2. ì´ë²ˆ ìˆ˜ì§‘ ë‚´ ë¹„êµ
        for accepted in unique_rows:
            if is_similar(new_title_norm, accepted["_title_norm"]):
                is_duplicate = True
                break
        
        if not is_duplicate:
            unique_rows.append(row)

    df_to_process = pd.DataFrame(unique_rows)
    print(f"ğŸ” {len(raw_rows)}ê±´ ì¤‘ ì¤‘ë³µ ì œê±° í›„ {len(df_to_process)}ê±´ ì²˜ë¦¬ ì‹œì‘.")

    processed_rows = []
    for idx, row in df_to_process.iterrows():
        print(f"   Processing: {row['ì œëª©'][:20]}...")
        target_url = row["ì›ë¬¸ë§í¬"]
        keyword = row["í‚¤ì›Œë“œ"]
        api_desc = row["_api_desc"]
        
        content = extract_article_content(target_url)
        summary = ""
        
        if content:
            if keyword not in content and keyword not in row['ì œëª©']:
                print(f"   âŒ [ì œì™¸] ë³¸ë¬¸ì— '{keyword}' ì—†ìŒ")
                continue 
            summary = summarize_article(content)
            time.sleep(2)
        
        # â˜… ìµœì¢… ì•ˆì „ì¥ì¹˜: AIê°€ ì‹¤íŒ¨í•˜ë©´ ë„¤ì´ë²„ ìš”ì•½ ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤Œ (ì—ëŸ¬ ë©”ì‹œì§€ X)
        if not summary:
            # AI ë³µì› ì‹œë„
            restored = repair_snippet(api_desc)
            if restored:
                summary = restored
            else:
                # AIê°€ ì™„ì „ ì£½ì—ˆìœ¼ë©´ ê·¸ëƒ¥ ë„¤ì´ë²„ ìš”ì•½ì´ë¼ë„ ë³´ì—¬ì¤Œ (ë¹ˆì¹¸ë³´ë‹¤ëŠ” ë‚˜ìŒ)
                summary = f"- {api_desc} (ë‚´ìš© í™•ì¸ í•„ìš”)"
            
        row["ìš”ì•½"] = summary
        processed_rows.append(row)

    if processed_rows:
        df_new_processed = pd.DataFrame(processed_rows)
        send_email_report(df_new_processed, target_date_str)
    else:
        print("ğŸ§¹ ì²˜ë¦¬í•  ì‹ ê·œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        df_new_processed = pd.DataFrame(columns=req_cols)

    df_final_new = df_new_processed[req_cols] if not df_new_processed.empty else pd.DataFrame(columns=req_cols)
    combined = pd.concat([df_existing, df_final_new], ignore_index=True)
    combined = combined.drop_duplicates(subset=["_title_norm"], keep="last")
    combined = combined.sort_values("ìˆ˜ì§‘ì‹œê°(KST)", ascending=False)

    display_cols = ["í‚¤ì›Œë“œ","ì œëª©","ìš”ì•½","ì›ë¬¸ë§í¬","ë°œí–‰ì¼(KST)","ìˆ˜ì§‘ì‹œê°(KST)"]
    combined[display_cols].to_csv(DATA_DIR / "ALL.csv", index=False, encoding="utf-8-sig")
    
    if not df_new_processed.empty:
        df_new_processed[display_cols].to_csv(DATA_DIR / "NEW_latest.csv", index=False, encoding="utf-8-sig")
    
    print("ğŸ‰ ì™„ë£Œ")

if __name__ == "__main__":
    main()
