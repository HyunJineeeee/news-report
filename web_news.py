# web_news.py
import requests
import pandas as pd
import os
import smtplib
import time
import re
from pathlib import Path
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import google.generativeai as genai
from datetime import datetime, timedelta
import trafilatura
import difflib # â˜… í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¹„êµ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ============== ì„¤ì • ==============
KEYWORDS = ["ì¼í•™ìŠµë³‘í–‰", "ì§ì—…í›ˆë ¨", "ê³ ìš©ë…¸ë™ë¶€", "í•œêµ­ì‚°ì—…ì¸ë ¥ê³µë‹¨"]
DATA_DIR = Path("data")

# â˜… ì¤‘ë³µ ì œê±° ê¸°ì¤€ (0.5 = 50% ì´ìƒ ë¹„ìŠ·í•˜ë©´ ì¤‘ë³µ ì²˜ë¦¬)
SIMILARITY_THRESHOLD = 0.5 

# í‚¤ì›Œë“œë³„ ìƒ‰ìƒ
KEYWORD_COLORS = {
    "ì¼í•™ìŠµë³‘í–‰": "#3498db",      # íŒŒë‘
    "ì§ì—…í›ˆë ¨": "#e67e22",        # ì£¼í™©
    "ê³ ìš©ë…¸ë™ë¶€": "#7f8c8d",      # íšŒìƒ‰
    "í•œêµ­ì‚°ì—…ì¸ë ¥ê³µë‹¨": "#2c3e50" # ë‚¨ìƒ‰
}

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
EMAIL_USER = os.environ.get("EMAIL_USER")
EMAIL_PASSWORD = os.environ.get("EMAIL_PASSWORD")
EMAIL_RECEIVER = os.environ.get("EMAIL_RECEIVER")
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ============== ìœ í‹¸ ==============
def clean_html(raw_html):
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.replace("&quot;", "'").replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")

def normalize_title(title):
    """íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë¹„êµìš© ë¬¸ìì—´ ìƒì„±"""
    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', title)

def is_similar(text1, text2):
    """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ê°€ ì„¤ì •ê°’(50%) ì´ìƒì¸ì§€ í™•ì¸"""
    if not text1 or not text2: return False
    # SequenceMatcherë¥¼ ì´ìš©í•´ ìœ ì‚¬ë„(0.0 ~ 1.0) ê³„ì‚°
    similarity = difflib.SequenceMatcher(None, text1, text2).ratio()
    return similarity >= SIMILARITY_THRESHOLD

# ============== AI & ë³¸ë¬¸ ì¶”ì¶œ ==============
def extract_article_content(url: str) -> str:
    if not url: return ""
    try:
        # 1. Trafilatura
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)
            if text and len(text) >= 100: return text
        
        # 2. Requests (Fallback)
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
        resp = requests.get(url, headers=headers, timeout=5)
        if resp.status_code == 200:
            text = trafilatura.extract(resp.text, include_comments=False)
            if text and len(text) >= 100: return text
        return ""
    except: return ""

def summarize_with_gemini(text: str) -> str:
    if not GEMINI_API_KEY or not text: return ""
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = (
            "ë„ˆëŠ” ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ê°€ì•¼. ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  í•µì‹¬ ë‚´ìš©ì„ 2~3ì¤„ë¡œ ìš”ì•½í•´ì¤˜.\n"
            "í˜•ì‹: '- 'ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥.\n"
            "ì–´ì¡°: ê±´ì¡°í•˜ê³  ê°ê´€ì ì¸ ë³´ê³ ì„œì²´.\n\n"
            f"í…ìŠ¤íŠ¸:\n{text[:4000]}"
        )
        response = model.generate_content(prompt)
        return response.text.strip()
    except: return ""

# ============== ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ==============
def crawl_naver_news(keyword, target_date_str):
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        print("[ERROR] ë„¤ì´ë²„ API í‚¤ ëˆ„ë½")
        return []

    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    
    # ë„‰ë„‰í•˜ê²Œ 100ê°œ ê°€ì ¸ì™€ì„œ í•„í„°ë§
    params = {"query": keyword, "display": 100, "start": 1, "sort": "date"}

    try:
        resp = requests.get(url, headers=headers, params=params)
        resp.raise_for_status()
        data = resp.json()
    except Exception as e:
        print(f"   [API Error] {e}")
        return []

    rows = []
    collected_at = pd.Timestamp.now(tz="Asia/Seoul").strftime("%Y-%m-%d %H:%M")
    
    for item in data.get('items', []):
        try:
            pub_date_dt = datetime.strptime(item['pubDate'], "%a, %d %b %Y %H:%M:%S +0900")
            pub_date_str = pub_date_dt.strftime("%Y-%m-%d %H:%M")
            pub_date_day = pub_date_dt.strftime("%Y-%m-%d")
        except: continue

        if pub_date_day != target_date_str: continue
            
        final_link = item['originallink'] if item['originallink'] else item['link']
        if not final_link: continue

        title = clean_html(item['title'])
        desc = clean_html(item['description'])
        
        rows.append({
            "í‚¤ì›Œë“œ": keyword,
            "ì œëª©": title,
            "ì›ë¬¸ë§í¬": final_link,
            "ì¶œì²˜": "NaverAPI",
            "ë°œí–‰ì¼(KST)": pub_date_str,
            "ìˆ˜ì§‘ì‹œê°(KST)": collected_at,
            "ìš”ì•½": "",
            "_api_desc": desc,
            "_title_norm": normalize_title(title)
        })
    return rows

# ============== ì´ë©”ì¼ ë°œì†¡ ==============
def send_email_report(df_new, target_date_str):
    if not EMAIL_USER or not EMAIL_PASSWORD or not EMAIL_RECEIVER: return
    if df_new.empty: return

    subject = f"[ì¼ë³‘ë¦¬í¬íŠ¸] {target_date_str} ì£¼ìš” ë‰´ìŠ¤ ì•Œë¦¼"

    html_body = f"""
    <div style="font-family: 'Malgun Gothic', sans-serif; background-color: #f4f4f4; padding: 20px; color: #333;">
        <div style="max-width: 700px; margin: 0 auto; background-color: #ffffff; padding: 30px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
            <div style="text-align: center; margin-bottom: 30px; border-bottom: 2px solid #555; padding-bottom: 20px;">
                <h1 style="color: #2c3e50; font-size: 24px; margin: 0;">ğŸ“° {target_date_str} ë‰´ìŠ¤ ë¦¬í¬íŠ¸</h1>
                <p style="color: #7f8c8d; font-size: 14px; margin-top: 10px;">
                    ì–´ì œ ìˆ˜ì§‘ëœ ì´ <span style="color:#e67e22; font-weight:bold;">{len(df_new)}</span>ê±´ì˜ ê¸°ì‚¬ ìš”ì•½ì…ë‹ˆë‹¤.
                </p>
            </div>
    """

    grouped = df_new.groupby("í‚¤ì›Œë“œ")
    for kw in KEYWORDS:
        if kw in grouped.groups:
            group_df = grouped.get_group(kw)
            kw_color = KEYWORD_COLORS.get(kw, "#333333")
            
            html_body += f"""
            <div style="margin-bottom: 30px;">
                <div style="background-color: {kw_color}; color: white; padding: 6px 15px; display: inline-block; border-radius: 15px; font-weight: bold; font-size: 16px; margin-bottom: 15px;">
                    # {kw}
                </div>
            """
            for idx, row in group_df.iterrows():
                title = row['ì œëª©']
                link = row['ì›ë¬¸ë§í¬']
                date = row['ë°œí–‰ì¼(KST)']
                summary = row['ìš”ì•½']
                summary_html = summary.replace('\n', '<br>')
                border_color = kw_color if "- " in summary else "#ddd"
                
                html_body += f"""
                <div style="border: 1px solid #e0e0e0; border-radius: 8px; padding: 20px; margin-bottom: 15px; background-color: #fff;">
                    <a href="{link}" target="_blank" style="font-size: 18px; font-weight: bold; color: #2c3e50; text-decoration: none; display: block; margin-bottom: 8px; line-height: 1.4;">
                        {title}
                    </a>
                    <div style="font-size: 12px; color: #95a5a6; margin-bottom: 15px;">
                        {date}
                    </div>
                    <div style="background-color: #f9f9f9; padding: 15px; border-left: 4px solid {border_color}; color: #555; font-size: 14px; line-height: 1.6; border-radius: 4px;">
                        {summary_html}
                    </div>
                    <div style="text-align: right; margin-top: 10px;">
                        <a href="{link}" target="_blank" style="display: inline-block; background-color: #ecf0f1; color: #555; padding: 5px 12px; border-radius: 4px; text-decoration: none; font-size: 12px;">
                            ì›ë¬¸ ë³´ëŸ¬ê°€ê¸° â†’
                        </a>
                    </div>
                </div>
                """
            html_body += '</div>'

    html_body += """
            <div style="text-align: center; margin-top: 40px; font-size: 12px; color: #bdc3c7; border-top: 1px solid #eee; padding-top: 20px;">
                Automated by GitHub Actions & Naver API
            </div>
        </div>
    </div>
    """

    try:
        msg = MIMEMultipart()
        msg['Subject'] = subject
        msg['From'] = EMAIL_USER
        msg['To'] = EMAIL_RECEIVER
        msg.attach(MIMEText(html_body, 'html'))

        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(EMAIL_USER, EMAIL_PASSWORD)
            server.send_message(msg)
        print(f"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ! ({subject})")
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

# ============== ë©”ì¸ ==============
def main():
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    now_kst = pd.Timestamp.now(tz="Asia/Seoul")
    yesterday_kst = now_kst - pd.Timedelta(days=1)
    target_date_str = yesterday_kst.strftime("%Y-%m-%d")
    print(f"ğŸ¯ íƒ€ê²Ÿ ë‚ ì§œ(ì–´ì œ): {target_date_str}")

    all_path = DATA_DIR / "ALL.csv"
    req_cols = ["í‚¤ì›Œë“œ","ì œëª©","ì›ë¬¸ë§í¬","ë°œí–‰ì¼(KST)","ìˆ˜ì§‘ì‹œê°(KST)","ì¶œì²˜","ìš”ì•½","_api_desc","_title_norm"]
    
    if all_path.exists():
        df_existing = pd.read_csv(all_path, dtype=str, encoding="utf-8-sig")
        for c in req_cols: 
            if c not in df_existing.columns: df_existing[c] = ""
        # ê¸°ì¡´ DB ì œëª©ë“¤ (ì¤‘ë³µ ë°©ì§€ìš©)
        existing_titles = list(df_existing["_title_norm"].dropna().astype(str))
    else:
        df_existing = pd.DataFrame(columns=req_cols)
        existing_titles = []

    # í¬ë¡¤ë§
    raw_rows = []
    for kw in KEYWORDS:
        print(f"ğŸ“¡ ìˆ˜ì§‘ ì¤‘ (Naver): {kw}...")
        raw_rows.extend(crawl_naver_news(kw, target_date_str))
        time.sleep(0.5)
    
    if not raw_rows: 
        print(f"ğŸ“… {target_date_str} ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # â˜…â˜…â˜… ê°•ë ¥í•œ ì¤‘ë³µ ì œê±° (ìœ ì‚¬ë„ 50% ê¸°ì¤€) â˜…â˜…â˜…
    unique_rows = []
    print("ğŸ§¹ ì¤‘ë³µ ì œê±°(ìœ ì‚¬ë„ 50%) ìˆ˜í–‰ ì¤‘...")
    
    for row in raw_rows:
        new_title_norm = row["_title_norm"]
        is_duplicate = False
        
        # 1. ê¸°ì¡´ DBì™€ ë¹„êµ
        for exist_title in existing_titles:
            if is_similar(new_title_norm, exist_title):
                is_duplicate = True
                break
        
        if is_duplicate: continue

        # 2. ì´ë²ˆ ìˆ˜ì§‘ ëª©ë¡ ë‚´ ë¹„êµ (ë°©ê¸ˆ ì¶”ê°€í•œ ê²ƒë“¤ê³¼ ë¹„êµ)
        for accepted in unique_rows:
            if is_similar(new_title_norm, accepted["_title_norm"]):
                is_duplicate = True
                break
        
        if not is_duplicate:
            unique_rows.append(row)
            # (ì£¼ì˜: ê¸°ì¡´ DB ë¦¬ìŠ¤íŠ¸ì—ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ - ì´ë²ˆ ë£¨í”„ ì„±ëŠ¥ ìœ„í•´)

    df_to_process = pd.DataFrame(unique_rows)
    print(f"ğŸ” {len(raw_rows)}ê±´ ì¤‘ ì¤‘ë³µ ì œê±° í›„ {len(df_to_process)}ê±´ ì²˜ë¦¬ ì‹œì‘.")

    processed_rows = []
    for idx, row in df_to_process.iterrows():
        print(f"   Processing: {row['ì œëª©'][:20]}...")
        real_url = row["ì›ë¬¸ë§í¬"]
        keyword = row["í‚¤ì›Œë“œ"]
        api_desc = row["_api_desc"]
        
        content = extract_article_content(real_url)
        summary = ""
        
        if content:
            # ë³¸ë¬¸ í•„í„°ë§
            if keyword not in content and keyword not in row['ì œëª©']:
                print(f"   âŒ [ì œì™¸] ë³¸ë¬¸ì— '{keyword}' ì—†ìŒ")
                continue 

            summary = summarize_with_gemini(content)
            time.sleep(2)
        
        if not summary or "ë¶€ì¡±í•©ë‹ˆë‹¤" in summary:
            if api_desc:
                summary = f"- (ë³¸ë¬¸ ì ‘ì† ë¶ˆê°€ë¡œ ìš”ì•½ ëŒ€ì²´) {api_desc}..."
            else:
                summary = "- ìš”ì•½í•  ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            
        row["ìš”ì•½"] = summary
        processed_rows.append(row)

    if processed_rows:
        df_new_processed = pd.DataFrame(processed_rows)
        send_email_report(df_new_processed, target_date_str)
    else:
        print("ğŸ§¹ ì²˜ë¦¬í•  ì‹ ê·œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        df_new_processed = pd.DataFrame(columns=req_cols)

    # ì €ì¥
    df_final_new = df_new_processed[req_cols] if not df_new_processed.empty else pd.DataFrame(columns=req_cols)
    combined = pd.concat([df_existing, df_final_new], ignore_index=True)
    # ì €ì¥í•  ë•ŒëŠ” í˜¹ì‹œ ëª¨ë¥¼ ì™„ì „ ë™ì¼ ì¤‘ë³µ í•œ ë²ˆ ë” ì œê±°
    combined = combined.drop_duplicates(subset=["_title_norm"], keep="last")
    combined = combined.sort_values("ìˆ˜ì§‘ì‹œê°(KST)", ascending=False)

    display_cols = ["í‚¤ì›Œë“œ","ì œëª©","ìš”ì•½","ì›ë¬¸ë§í¬","ë°œí–‰ì¼(KST)","ìˆ˜ì§‘ì‹œê°(KST)"]
    combined[display_cols].to_csv(DATA_DIR / "ALL.csv", index=False, encoding="utf-8-sig")
    
    if not df_new_processed.empty:
        df_new_processed[display_cols].to_csv(DATA_DIR / "NEW_latest.csv", index=False, encoding="utf-8-sig")
    
    print("ğŸ‰ ì™„ë£Œ")

if __name__ == "__main__":
    main()
